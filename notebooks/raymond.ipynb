{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-cpp-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import string\n",
    "import chromadb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import pipeline\n",
    "from llama_cpp import Llama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aberto', 'Accio', 'Aguamenti', 'Alohomora', 'Anapneo', 'Aparecium', 'Apparate', 'Ascendio', 'Avada Kedavra', 'Avis', 'Bat-Bogey Hex', 'Bombardo', 'Brackium Emendo', 'Capacious Extremis', 'Confundo', 'Conjunctivitis Curse', 'Crinus Muto', 'Crucio', 'Diffindo', 'Disillusionment Charm', 'Disapparate', 'Engorgio', 'Episkey', 'Expecto patronum', 'Erecto', 'Evanesco', 'Expelliarmus', 'Ferula', 'Fidelius Charm', 'Fiendfyre Curse', 'Finite Incantatem', 'Furnunculus Curse', 'Geminio', 'Glisseo', 'Homenum Revelio', 'Homonculus Charm', 'Immobulus', 'Impedimenta', 'Incarcerous', '*Imperio', 'Impervius', 'Incendio', 'Langlock', 'Legilimens', 'Levicorpus', 'Locomotor Mortis', 'Lumos', 'Morsmordre', 'Mucus Ad Nauseam', 'Muffliato', 'Nox', 'Obliviate', 'Obscuro', 'Oculus Reparo', 'Oppugno', 'Petrificus Totalus', 'Periculum', 'Piertotum Locomotor', 'Protean Charm', 'Protego', 'Reducto', 'Reducio', 'Renneverate', 'Reparifors', 'Reparo', 'Rictusempra', 'Riddikulus', 'Scourgify', '*Sectumsempra', 'Serpensortia', 'Silencio', 'Sonorus', 'Spongify', 'Stupefy', 'Tarantallegra', 'Unbreakable Vow', 'Wingardium Leviosa']\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "metadata = []\n",
    "ids = []\n",
    "\n",
    "with open('data/spells.txt', 'r', encoding='utf-8') as spells:\n",
    "    for line in spells:\n",
    "        line=line.split(\" - \") #spells are separated by their description by a \" - \"\n",
    "        metadata.append({'spell': line[0]}) #use the spell name as metadata. ChromaDB requires a dictionary here\n",
    "        documents.append(line[1]) #use the description as documents\n",
    "        ids.append(line[0]) #we also need an ID so use the spell name again.\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "# create or open collection named 'spells' \n",
    "spells_collection = client.get_or_create_collection(\"spells\")\n",
    "\n",
    "# add spells to the collection, ignored for ids that already exist \n",
    "spells_collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadata,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['Lumos']],\n",
       " 'distances': [[1.327547311782837]],\n",
       " 'metadatas': [[{'spell': 'Lumos'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"Illuminates the caster's wand\\n\"]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input=\"How do I create light\"\n",
    "results = spells_collection.query(\n",
    "    query_texts=[user_input],\n",
    "    n_results=1\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lumos - Illuminates the caster's wand\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=results['metadatas'][0][0]['spell']+\" - \" + results['documents'][0][0][:-1]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement llama-cpp (from versions: none)\n",
      "ERROR: No matching distribution found for llama-cpp\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_cpp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_cpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Llama\n\u001b[0;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m Llama\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      4\u001b[0m \trepo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBramVanroy/GEITje-7B-ultra-GGUF\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m \tfilename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeitje-7b-ultra-f16.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m llm\u001b[38;5;241m.\u001b[39mcreate_chat_completion(\n\u001b[0;32m      9\u001b[0m \tmessages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m \t\t{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \t]\n\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_cpp'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "\trepo_id=\"BramVanroy/GEITje-7B-ultra-GGUF\",\n",
    "\tfilename=\"geitje-7b-ultra-q8_0.gguf\",\n",
    ")\n",
    "\n",
    "llm.create_chat_completion(\n",
    "\tmessages = [\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": \"What is the capital of France?\"\n",
    "\t\t}\n",
    "\t]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Recommended spell: {result}\n",
    "User input: {user_input} \n",
    "Suggest a spell based on the recommended spell and the user input.\"\"\"\n",
    "\n",
    "prompt=prompt.format(user_input=user_input, result=result)\n",
    "print (\"prompt: \", prompt)\n",
    "with tf.device('CPU: 0'): #Force on CPU for both apple silicon and low GPU mem configurations\n",
    "        inference = model.generate(prompt, max_length = 100)\n",
    "print(inference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
