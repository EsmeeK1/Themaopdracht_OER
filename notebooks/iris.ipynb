{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OER botje Themaopdracht\n",
    "\n",
    "### Notebook by [Iris Oerlemans](http://www.google.com/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "\n",
    "2. [The problem domain](#The-problem-domain)\n",
    "\n",
    "4. [Business Understanding](#Business-Understanding)\n",
    "\n",
    "5. [Required libraries](#Required-libraries)\n",
    "\n",
    "6. [Data Understanding](#Data-Understanding)\n",
    "\n",
    "7. [Data Prepartion](#Data-Preparation)\n",
    "\n",
    "8. [Modeling](#Modeling)\n",
    "\n",
    "9. [Evaluation](#Evaluation)\n",
    "\n",
    "10. [Reproducibility](#Reproducibility)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "In dit document wordt de toepassing van GUFF met 'geitje' met een semDB verkend. Uiteindelijk wordt hiermee een chatbot gemaakt die vragen kan beantwoorden over het OER (onderwijs en examenregelement). De opdracht komt van Hogeschool Windesheim. \n",
    "Hogeschool Windesheim is een Nederlandse instelling voor hoger onderwijs. De hogeschool biedt een breed aanbod aan bachelor en masteropleidingen op onder andere het gebied van techniek en sociale wetenschappen. \n",
    "Hogeschool Windesheim heeft verschillende vestigingen met ongeveer 1800 medewerkers.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "Windesheim ondervind dat leerlingen het onderwijs en examenregelement (OER) onvoldoende bestuderen. Hierom wil Windesheim graag een chatbot hebben zodat leerlingen hier hun vragen aan kwijt kunnen om zo de informatie makkelijker tot zich te nemen. \n",
    "\n",
    ">Wat gaan we oplossen\n",
    "\n",
    "*We lossen op dat leerlingen op een makkelijkere manier de informatie van het OER tot zich kunnen nemen*\n",
    "\n",
    ">Weet jij wat de KSF's zijn van het project?\n",
    "\n",
    "*Het project is succesvol als er een werkende chatbot in een python applicatie inclusief GUI gepresenteerd wordt met daarbij ook de onderbouwing van de gemaakte keuzes*\n",
    "\n",
    ">Wat is de context van de vraag?\n",
    " \n",
    "*De context van de vraag is het ontwikkelen van een chatbot die studenten helpt informatie te vinden over het OER. Studenten hebben vaak moeite om deze documenten goed te begrijpen.*\n",
    "\n",
    ">Is er een ontwerp of een eindvisie?\n",
    "\n",
    "*De eindvisie is om een werkende chatbot te creëeren met daarmee de mogelijkheid om vragen te kunnen stellen over het OER. Daarbij is het doel om de drempel voor het begrijpen van de belangrijke documenten te verlagen voor studenten.*\n",
    "\n",
    ">Kan de vraag worden opgelost met de gegeven dataset\n",
    "\n",
    "*De dataset die is aangeleverd is het OER(wordbestand). Er moet onderzoek worden gedaan hoe we deze kunnen omzetten om te kunnen gebruiken. Indien dit lukt kan de vraag worden opgelost met de gegeven dataset*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libraries\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "*korte uitleg over de packages die je gebruikt om het project werkende te krijgen, voorbeeld van een random notebook online:*\n",
    "\n",
    "If you don't have Python on your computer, you can use the [Anaconda Python distribution](http://continuum.io/downloads) to install most of the Python packages you need. Anaconda provides a simple double-click installer for your convenience.\n",
    "\n",
    "This notebook uses several Python packages that come standard with the Anaconda Python distribution. The primary libraries that we'll be using are:\n",
    "\n",
    "* **NumPy**: Provides a fast numerical array structure and helper functions.\n",
    "* **pandas**: Provides a DataFrame structure to store data in memory and work with it easily and efficiently.\n",
    "* **scikit-learn**: The essential Machine Learning package in Python.\n",
    "* **matplotlib**: Basic plotting library in Python; most other Python plotting libraries are built on top of it.\n",
    "* **Seaborn**: Advanced statistical plotting library.\n",
    "* **watermark**: A Jupyter Notebook extension for printing timestamps, version numbers, and hardware information.\n",
    "\n",
    "To make sure you have all of the packages you need, install them with `conda`:\n",
    "\n",
    "    conda install numpy pandas scikit-learn matplotlib seaborn\n",
    "    \n",
    "    conda install -c conda-forge watermark\n",
    "\n",
    "`conda` may ask you to update some of them if you don't have the most recent version. Allow it to do so.\n",
    "\n",
    "**Note:** I will not be providing support for people trying to run this notebook outside of the Anaconda Python distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 11:52:21.170416: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-15 11:52:22.600432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-15 11:52:23.006094: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-15 11:52:23.115735: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-15 11:52:23.790091: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "# Machine Learning and Data Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "\n",
    "# System and File Management\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# AI packages\n",
    "import tensorflow as tf # type: ignore\n",
    "\n",
    "# Add a path to the scripts directory\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'scripts')))\n",
    "\n",
    "# Project-Specific Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "*hier ga je echt diep de data in doormiddel van stapsgewijze analyze. Bijvoorbeeld:\n",
    "\n",
    ">eerst kijken wat in de data zit met df.head()\n",
    "\n",
    "\"Oh ik zie dat er veel data ontbreekt\" *verwijdert ontbrekende data*\n",
    "\n",
    ">df.describe()\n",
    "\n",
    "\"ik zie nu x\" *doe Y*\n",
    "\n",
    ">enzovoort\n",
    "\n",
    "*Het idee is dus dat je elke regel uitlegt waarom je wat doet. Je eindigt altijd met een opsomming van je bevindingen*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "*Simpel gezegd opschonen van je data tot het punt dat je het in een model kan stoppen, kan soms heel klein zijn of heel veel. Hier geldt ook weer, elke stap onderbouwen*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende code komt van de github van GEITje. Ik wil eerst GEITje werkend hebben en dan gaan puzzelen met het docuement toevoegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.4.1)\n",
      "Collecting einops (from flash-attn)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.6.3-cp311-cp311-linux_x86_64.whl size=187328293 sha256=25405479af3f6865c873ee3bbdfadcfccea9055355de78e7cd6b93170e9d4377\n",
      "  Stored in directory: /root/.cache/pip/wheels/e3/ef/b1/7889928ffa2dea61032e61480db4e4c20d00a9d9e28cd4f55a\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: einops, flash-attn\n",
      "Successfully installed einops-0.8.0 flash-attn-2.6.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flash-attn --no-build-isolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e63e42fe3f40578053a2a0106598bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Beperk GPU-geheugen gebruik\n",
    "torch.cuda.set_per_process_memory_fraction(0.5)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = 'Rijgersberg/GEITje-7B-chat-v2'  \n",
    "\n",
    "# Laad het model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, low_cpu_mem_usage=True).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate(conversation, temperature=0.2, top_k=50, max_new_tokens=100):  # Verminder max_new_tokens\n",
    "    tokenized = tokenizer.apply_chat_template(conversation, add_generation_prompt=True,\n",
    "                                              return_tensors='pt').to(device)\n",
    "    outputs = model.generate(tokenized, do_sample=True, temperature=temperature,\n",
    "                             top_k=top_k, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Welk woord hoort er niet in dit rijtje thuis: \"auto, vliegtuig, geitje, bus\"?'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(generate(conversation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "*Korte uitleg wat voor model je gebruikt en waarom*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "*Doormiddel van visualisaties laten zien waarom het wel of niet werkt en benoem de vervolgstappen voor vervolg onderzoek*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "*Als je notebook niet nagemaakt kan worden is het een slecht notebook, wat je hier kan benoemen is dat er een requirements.txt is met de versies en een compacte versie van je code in 1 codeblock*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan dit ook nog toevoegen:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Success:</b> This alert box indicates a successful or positive action.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Example:</b> Use yellow boxes for examples that are not inside code cells, or use for mathematical formulas if needed. Typically also used to display warning messages.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> Use blue boxes (alert-info) for tips and notes.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>Danger:</b> This alert box indicates a dangerous or potentially negative action.</div>\n",
    "\n",
    "Zo'n markdown block is gewoon HTML-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
